{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRsb33BVc5r6iULXkvkc9I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riyapalesha/SPPU-Data_Science_And_Big_Data_Analytics_Lab/blob/main/Assignment7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Analytics\n",
        "\n",
        "#PART1\n",
        "1. Extract Sample document and apply following document preprocessing methods:\n",
        "Tokenization, POS Tagging, stop words removal, Stemming and Lemmatization.\n"
      ],
      "metadata": {
        "id": "miAJM0t7rKoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import math"
      ],
      "metadata": {
        "id": "mk_BrnxQrI43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWZakXqPe8lK",
        "outputId": "b2e0c492-f77b-4fc2-9bb0-c6d1d4946515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I woke up to the sound of birds singing outside. The sun filled the room with warmth and light. I brewed a fresh cup of coffee and savored its rich aroma. Immersed in work, time slipped away as I typed on my keyboard. A gentle breeze refreshed me during a break. I inhaled the scent of blooming flowers, feeling at peace.\n"
          ]
        }
      ],
      "source": [
        "corpus = \"I woke up to the sound of birds singing outside. The sun filled the room with warmth and light. I brewed a fresh cup of coffee and savored its rich aroma. Immersed in work, time slipped away as I typed on my keyboard. A gentle breeze refreshed me during a break. I inhaled the scent of blooming flowers, feeling at peace.\"\n",
        "print(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Tokenization"
      ],
      "metadata": {
        "id": "LoizDOXbryUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize,sent_tokenize"
      ],
      "metadata": {
        "id": "KHUiAiqgrsKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klbmDxp5sYIP",
        "outputId": "2dd01af0-a18e-41ac-c80d-32c1168d0247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sent=sent_tokenize(corpus)\n",
        "tokenized_sent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCLr4A8vsLpE",
        "outputId": "f775ac88-93d0-4596-d3c8-070b00b8339d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I woke up to the sound of birds singing outside.',\n",
              " 'The sun filled the room with warmth and light.',\n",
              " 'I brewed a fresh cup of coffee and savored its rich aroma.',\n",
              " 'Immersed in work, time slipped away as I typed on my keyboard.',\n",
              " 'A gentle breeze refreshed me during a break.',\n",
              " 'I inhaled the scent of blooming flowers, feeling at peace.']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_words=word_tokenize(corpus)\n",
        "tokenized_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y0E11PhsVxe",
        "outputId": "7ec4333e-18f8-4335-e7cf-865d1342c6f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'woke',\n",
              " 'up',\n",
              " 'to',\n",
              " 'the',\n",
              " 'sound',\n",
              " 'of',\n",
              " 'birds',\n",
              " 'singing',\n",
              " 'outside',\n",
              " '.',\n",
              " 'The',\n",
              " 'sun',\n",
              " 'filled',\n",
              " 'the',\n",
              " 'room',\n",
              " 'with',\n",
              " 'warmth',\n",
              " 'and',\n",
              " 'light',\n",
              " '.',\n",
              " 'I',\n",
              " 'brewed',\n",
              " 'a',\n",
              " 'fresh',\n",
              " 'cup',\n",
              " 'of',\n",
              " 'coffee',\n",
              " 'and',\n",
              " 'savored',\n",
              " 'its',\n",
              " 'rich',\n",
              " 'aroma',\n",
              " '.',\n",
              " 'Immersed',\n",
              " 'in',\n",
              " 'work',\n",
              " ',',\n",
              " 'time',\n",
              " 'slipped',\n",
              " 'away',\n",
              " 'as',\n",
              " 'I',\n",
              " 'typed',\n",
              " 'on',\n",
              " 'my',\n",
              " 'keyboard',\n",
              " '.',\n",
              " 'A',\n",
              " 'gentle',\n",
              " 'breeze',\n",
              " 'refreshed',\n",
              " 'me',\n",
              " 'during',\n",
              " 'a',\n",
              " 'break',\n",
              " '.',\n",
              " 'I',\n",
              " 'inhaled',\n",
              " 'the',\n",
              " 'scent',\n",
              " 'of',\n",
              " 'blooming',\n",
              " 'flowers',\n",
              " ',',\n",
              " 'feeling',\n",
              " 'at',\n",
              " 'peace',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Stemming"
      ],
      "metadata": {
        "id": "foUNRFdfu7pP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmed_words=[]\n",
        "for word in tokenized_words:\n",
        "  stem_word=ps.stem(word)\n",
        "  stemmed_words.append(stem_word)\n",
        "\n",
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L70IuAxu_YJ",
        "outputId": "184ebb8c-90a6-48cd-b49f-621f44583c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'woke',\n",
              " 'up',\n",
              " 'to',\n",
              " 'the',\n",
              " 'sound',\n",
              " 'of',\n",
              " 'bird',\n",
              " 'sing',\n",
              " 'outsid',\n",
              " '.',\n",
              " 'the',\n",
              " 'sun',\n",
              " 'fill',\n",
              " 'the',\n",
              " 'room',\n",
              " 'with',\n",
              " 'warmth',\n",
              " 'and',\n",
              " 'light',\n",
              " '.',\n",
              " 'i',\n",
              " 'brew',\n",
              " 'a',\n",
              " 'fresh',\n",
              " 'cup',\n",
              " 'of',\n",
              " 'coffe',\n",
              " 'and',\n",
              " 'savor',\n",
              " 'it',\n",
              " 'rich',\n",
              " 'aroma',\n",
              " '.',\n",
              " 'immers',\n",
              " 'in',\n",
              " 'work',\n",
              " ',',\n",
              " 'time',\n",
              " 'slip',\n",
              " 'away',\n",
              " 'as',\n",
              " 'i',\n",
              " 'type',\n",
              " 'on',\n",
              " 'my',\n",
              " 'keyboard',\n",
              " '.',\n",
              " 'a',\n",
              " 'gentl',\n",
              " 'breez',\n",
              " 'refresh',\n",
              " 'me',\n",
              " 'dure',\n",
              " 'a',\n",
              " 'break',\n",
              " '.',\n",
              " 'i',\n",
              " 'inhal',\n",
              " 'the',\n",
              " 'scent',\n",
              " 'of',\n",
              " 'bloom',\n",
              " 'flower',\n",
              " ',',\n",
              " 'feel',\n",
              " 'at',\n",
              " 'peac',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Lemmatization\n",
        "\n"
      ],
      "metadata": {
        "id": "6cv_WbMBsqcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lm=WordNetLemmatizer()\n",
        "\n",
        "lemmatised_words=[]\n",
        "for word in tokenized_words:\n",
        "  lemma=lm.lemmatize(word)\n",
        "  lemmatised_words.append(lemma)\n",
        "lemmatised_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtB_ak6Zsl9Q",
        "outputId": "956e2bf8-ed0c-4b6b-ef78-2dda078d7724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'woke',\n",
              " 'up',\n",
              " 'to',\n",
              " 'the',\n",
              " 'sound',\n",
              " 'of',\n",
              " 'bird',\n",
              " 'singing',\n",
              " 'outside',\n",
              " '.',\n",
              " 'The',\n",
              " 'sun',\n",
              " 'filled',\n",
              " 'the',\n",
              " 'room',\n",
              " 'with',\n",
              " 'warmth',\n",
              " 'and',\n",
              " 'light',\n",
              " '.',\n",
              " 'I',\n",
              " 'brewed',\n",
              " 'a',\n",
              " 'fresh',\n",
              " 'cup',\n",
              " 'of',\n",
              " 'coffee',\n",
              " 'and',\n",
              " 'savored',\n",
              " 'it',\n",
              " 'rich',\n",
              " 'aroma',\n",
              " '.',\n",
              " 'Immersed',\n",
              " 'in',\n",
              " 'work',\n",
              " ',',\n",
              " 'time',\n",
              " 'slipped',\n",
              " 'away',\n",
              " 'a',\n",
              " 'I',\n",
              " 'typed',\n",
              " 'on',\n",
              " 'my',\n",
              " 'keyboard',\n",
              " '.',\n",
              " 'A',\n",
              " 'gentle',\n",
              " 'breeze',\n",
              " 'refreshed',\n",
              " 'me',\n",
              " 'during',\n",
              " 'a',\n",
              " 'break',\n",
              " '.',\n",
              " 'I',\n",
              " 'inhaled',\n",
              " 'the',\n",
              " 'scent',\n",
              " 'of',\n",
              " 'blooming',\n",
              " 'flower',\n",
              " ',',\n",
              " 'feeling',\n",
              " 'at',\n",
              " 'peace',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# POS Tagging"
      ],
      "metadata": {
        "id": "qav6m4vKxrN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# POS Tagging\n",
        "#CC: Coordinating Conjunction, CD: Cardinal Number, DT: Determiner, IN: Preposition, JJ: Adjective, MD: Modal, NN: Noun, NNS: Noun, Plural, NNP: Proper Noun, Singular, NNPS: Proper Noun, Plural\n",
        "#PRP: Personal Pronoun,  PRP$: Possessive Pronoun, RB: Adverb, TO: Infinitival \"to\",VB: Verb, Base Form, WP: Wh-Pronoun\n",
        "\n",
        "print(\"Parts Of Speech: \",nltk.pos_tag(tokenized_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kox9ja3jsptw",
        "outputId": "cdc53483-7357-4467-8510-28697e351357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parts Of Speech:  [('I', 'PRP'), ('woke', 'VBD'), ('up', 'RB'), ('to', 'TO'), ('the', 'DT'), ('sound', 'NN'), ('of', 'IN'), ('birds', 'NNS'), ('singing', 'VBG'), ('outside', 'JJ'), ('.', '.'), ('The', 'DT'), ('sun', 'NN'), ('filled', 'VBD'), ('the', 'DT'), ('room', 'NN'), ('with', 'IN'), ('warmth', 'NN'), ('and', 'CC'), ('light', 'NN'), ('.', '.'), ('I', 'PRP'), ('brewed', 'VBD'), ('a', 'DT'), ('fresh', 'JJ'), ('cup', 'NN'), ('of', 'IN'), ('coffee', 'NN'), ('and', 'CC'), ('savored', 'VBD'), ('its', 'PRP$'), ('rich', 'JJ'), ('aroma', 'NN'), ('.', '.'), ('Immersed', 'VBN'), ('in', 'IN'), ('work', 'NN'), (',', ','), ('time', 'NN'), ('slipped', 'VBD'), ('away', 'RB'), ('as', 'IN'), ('I', 'PRP'), ('typed', 'VBD'), ('on', 'IN'), ('my', 'PRP$'), ('keyboard', 'NN'), ('.', '.'), ('A', 'DT'), ('gentle', 'JJ'), ('breeze', 'NN'), ('refreshed', 'VBD'), ('me', 'PRP'), ('during', 'IN'), ('a', 'DT'), ('break', 'NN'), ('.', '.'), ('I', 'PRP'), ('inhaled', 'VBD'), ('the', 'DT'), ('scent', 'NN'), ('of', 'IN'), ('blooming', 'VBG'), ('flowers', 'NNS'), (',', ','), ('feeling', 'VBG'), ('at', 'IN'), ('peace', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Stop Word Removal"
      ],
      "metadata": {
        "id": "joqSyVmN6zjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords_in_english=stopwords.words('english')\n",
        "print(stopwords_in_english)\n",
        "words=[word for word in corpus.split() if word.lower() not in stopwords_in_english]\n",
        "new_corpus=' '.join(words)\n",
        "print(new_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKRqiHB_5b6D",
        "outputId": "04f7b366-9fc9-4d72-9927-b6eea122f168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
            "woke sound birds singing outside. sun filled room warmth light. brewed fresh cup coffee savored rich aroma. Immersed work, time slipped away typed keyboard. gentle breeze refreshed break. inhaled scent blooming flowers, feeling peace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PART2\n",
        "2. Create representation of document by calculating Term Frequency and Inverse Document\n",
        "Frequency.\n"
      ],
      "metadata": {
        "id": "OEvo5xz37YE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_term_frequency(text):\n",
        "  text=text.lower()\n",
        "  tokens=text.split(' ')\n",
        "\n",
        "  freq={}\n",
        "  for token in tokens:\n",
        "    freq[token]=freq.get(token,0)+1\n",
        "\n",
        "  return freq"
      ],
      "metadata": {
        "id": "1RpsYxss6uE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_text = \"This is a text from a sample document which is used for calculating the term frequency.\"\n",
        "tf = calculate_term_frequency(document_text)\n",
        "print(tf)\n",
        "#higher the term frequency more important is the word in the document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-W0frNg7ycQ",
        "outputId": "bb42d5cb-796d-480e-b661-f9ffc9c1c7b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'this': 1, 'is': 2, 'a': 2, 'text': 1, 'from': 1, 'sample': 1, 'document': 1, 'which': 1, 'used': 1, 'for': 1, 'calculating': 1, 'the': 1, 'term': 1, 'frequency.': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_inverse_document_frequency(documents):\n",
        "  tokenized_docs=[]\n",
        "  for doc in documents:\n",
        "    tokenized_docs.append(doc.lower().split(' '))\n",
        "\n",
        "  document_freq={}\n",
        "  for doc in tokenized_docs:\n",
        "    unique_words=set(doc)\n",
        "    for word in unique_words:\n",
        "      document_freq[word]=document_freq.get(word,0)+1\n",
        "\n",
        "  num=len(tokenized_docs)\n",
        "  inverse_document_frequency = {}\n",
        "  for term,df in document_freq.items():\n",
        "    inverse_document_frequency[term]=math.log(num/df)\n",
        "\n",
        "  return inverse_document_frequency"
      ],
      "metadata": {
        "id": "tIGl6Jfx74iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documentList = [\n",
        "      \"This is the first document\",\n",
        "      \"This document is the second document\",\n",
        "      \"And this is the third one\",\n",
        "      \"Is this the first document?\"\n",
        "  ]\n",
        "\n",
        "idf_scores = calculate_inverse_document_frequency(documentList)\n",
        "for term, score in idf_scores.items():\n",
        "    print(f\"Term: {term}, IDF: {score}\")\n",
        "    print(\"-----------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLRSut_r7957",
        "outputId": "de4e7390-592f-4677-f446-ab83d4e912c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Term: this, IDF: 0.0\n",
            "-----------------------------------------\n",
            "Term: is, IDF: 0.0\n",
            "-----------------------------------------\n",
            "Term: first, IDF: 0.6931471805599453\n",
            "-----------------------------------------\n",
            "Term: document, IDF: 0.6931471805599453\n",
            "-----------------------------------------\n",
            "Term: the, IDF: 0.0\n",
            "-----------------------------------------\n",
            "Term: second, IDF: 1.3862943611198906\n",
            "-----------------------------------------\n",
            "Term: third, IDF: 1.3862943611198906\n",
            "-----------------------------------------\n",
            "Term: one, IDF: 1.3862943611198906\n",
            "-----------------------------------------\n",
            "Term: and, IDF: 1.3862943611198906\n",
            "-----------------------------------------\n",
            "Term: document?, IDF: 1.3862943611198906\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    }
  ]
}